---
title: "**ENV222 NOTE**"
subtitle: "*R in statistics (Advanced)*"
author:
  - "TC-tea"
date: "`r Sys.Date()`"
date-format: "YYYY.MM.DD"
output:
  quarto::quarto_document:
    default_output_format: html
    code:
      pandoc_args: ["-V", "lang=en"]
    df_print: paged
toc: true
toc-location: left
fontsize: 12pt
fontfamily: Tahoma
theme: default
comments:
  hypothesis: true
---

<head>
  <!-- Set viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Set styles for light and dark mode -->
  <style>
    mark {
      background-color: yellow;
    }
    .dark-mode {
      background-color: black;
      color: white;
    }
    .light-code {
      color: black;
    }
    .dark-code {
      color: white;
    }
    .quarto-output pre:not([class*="language-"]) {
      background-color: transparent;
      color: inherit;
    }
    .quarto-output pre[class*="language-"] {
      background-color: #F5F5F5;
      color: black;
    }
    .dark-mode .quarto-output pre[class*="language-"] {
      background-color: #2B2B2B;
      color: white;
    }
    /* CSS for back-to-top button */
    #back-to-top {
      position: fixed;
      bottom: 10px;
      right: 22px;
      font-size: 22px;
      border-radius: 50%;
      width: 35px;
      height: 35px;
      text-decoration: none;
    }
    /* CSS for light/dark mode toggle button */
    #myBtn {
      position: fixed;
      top: 20px;
      left: 20px;
      border: none;
      border-radius: 10px;
      padding: 8px;
      background-color: lightgray;
    }
    #myBtn:before {
      content: "☀";
    }
    .dark-mode #myBtn:before {
      content: "🌙";
    }
  </style>
</head>

<body>
  <!-- Button to toggle light/dark mode -->
  <button id="myBtn" onclick="myFunction()"></button>
  <script>
    function myFunction() {
      var element = document.body;
      element.classList.toggle("dark-mode");
      var codeBlocks = document.querySelectorAll(".quarto-output pre[class*='language-']");
      codeBlocks.forEach(function(block) {
        block.classList.toggle("light-code");
        block.classList.toggle("dark-code");
      });
    }
  </script>
  <!-- Button to scroll back to top of page -->
<a href="#" id="back-to-top" title="Back to top">🚀</a>
</body>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = "center")
```

<details>
  <summary>Hyperlink of XJTLU ENV222 courseware</summary>
- [Lecture1 ENV222 Overview](https://pzhao.org/openr/ENV222-Overview.html)<br>
- [Lecture2 R Markdown basic](https://pzhao.org/openr/R-markdown-basic.html)<br>
- [Lecture3 R Markdown advanced](https://pzhao.org/openr/R-markdown-advanced.html)<br>
- [Lecture4 R for characters](https://pzhao.org/openr/R-characters.html)<br>
- [Lecture5 R for time data](https://pzhao.org/openr/R-time.html)<br>
- [Lecture6 Statistical graphs (advanced)](https://pzhao.org/openr/R-graphs-advanced.html)<br>
- [Lecture7 R Tidyverse](https://pzhao.org/openr/R-Tidyverse.html)<br>
- [Lecture8 ANOVA Post-hoc tests](https://pzhao.org/openr/ANOVA-post-hoc.html)<br>
- [Lecture9 MANOVA](https://pzhao.org/openr/MANOVA.html)<br>
- [Lecture10 ANCOVA](https://pzhao.org/openr/ANCOVA.html)<br>
- [Lecture11 MANCOVA](https://pzhao.org/openr/MANCOVA.html)<br>
- [Lecture12 Combining statistics](https://pzhao.org/openr/Combining-statistics.html)<br>
- [Lecture13 Non-parametric hypothesis tests](https://pzhao.org/openr/Non-parametric-hypothesis-tests.html)<br>
- [Lecture14 Multiple linear regression](https://pzhao.org/openr/Multiple-linear-regression.html)<br>
- [Lecture15 Logistic regression](https://pzhao.org/openr/Logistic-regression.html)<br>
- [Lecture16 Poisson regression](https://pzhao.org/openr/Poisson-regression.html)<br>
- [Lecture17 Non-linear regression](https://pzhao.org/openr/Non-linear-regression.html)<br>
- [Lecture18 Principal component analysis](https://pzhao.org/openr/Principal-component-analysis.html)<br>
- [Lecture19 Cluster analysis](https://pzhao.org/openr/Cluster-analysis.html)<br>
</details>

<details>
  <summary>The meaning of each parameter in statistical table (Chinese)</summary>
- Df（自由度）: 回归自由度（regression degrees of freedom）和误差自由度（error degrees of freedom）的总数，其中回归自由度为解释变量的个数减1，误差自由度为样本量减去解释变量的个数。
- Sum Sq（平方和）: 每个来源的平方和（sum of squares），是变量离均差的平方和。回归平方和（regression sum of squares）表示自变量对因变量的影响程度，误差平方和（error sum of squares）表示自变量未能解释的部分。
- Mean Sq（均方）: 每个来源的均方（mean square），是平方和除以自由度得到的平均数。回归均方（regression mean square）表示每个自变量对因变量的影响程度，误差均方（error mean square）表示自变量未能解释的部分的平均方差。
- F value: 回归均方与误差均方的比值，用于判断模型的拟合程度，F值越大则模型越好。在一元线性回归中，F值等于t值的平方。
- Pr(>F): Probability of obtaining a larger F value（得到更大的F值的概率）Pr(>F)是F检验得到的P值。p值越小则说明结果越显著，一般将显著性水平设为0.05，即当p值小于0.05时认为结果具有统计显著性。
- Pillai: Pillai trace（皮莱迹）是在多元方差分析中使用的一种统计量，用于衡量所有因素对因变量的共同影响程度。
- approx F: F approximation（F近似值）是根据Pillai迹值计算出来的F值。它用于评估多元方差分析的总体显著性。
- num Df: Numerator degrees of freedom（分子自由度）指的是分子中的自由度。
- den Df: Denominator degrees of freedom（分母自由度）指的是分母中的自由度。
- Residuals: 残差，是指多元方差分析中的误差项，即不能被自变量解释的因变量方差。
- Intercept: 截距，也称为常数项，表示当自变量为0时，因变量的预测值（或期望值）。
- Estimate: 回归系数，表示自变量每增加一个单位时，因变量发生的平均变化量。
- Std.Error: 标准误差，表示估计值的不确定性或误差，即估计值与真实值之间的平均差异。
- t value: t值，表示回归系数的显著性，即回归系数除以其标准误差，得到的值与t分布相比较的结果。
</details>

<details>
  <summary>How to choose between ANOVA, MANOVA, ANCOVA and MANCOVA (Chinese)</summary>
ANOVA、MANOVA、ANCOVA和MANCOVA都是统计学中常见的分析方法，主要用于比较两个或多个组之间的差异性，并用统计学方法对这些差异进行推断和验证。

- ANOVA（Analysis of Variance）：方差分析，用于比较两个或多个组的均值是否有显著差异，适用于只有一个自变量和一个因变量的情况。例如，用于比较不同教学方法对学生成绩的影响是否有显著差异。
- MANOVA（Multivariate Analysis of Variance）：多元方差分析，用于比较两个或多个组的多个相关因变量是否有显著差异，适用于有多个相关因变量的情况。例如，用于比较不同教学方法对学生成绩、学生态度和学生动机等多个方面的影响是否有显著差异。
- ANCOVA（Analysis of Covariance）：协方差分析，用于比较两个或多个组的均值是否有显著差异，并控制一个或多个协变量（即影响因素），适用于需要控制其他因素影响的情况。例如，用于比较不同教学方法对学生成绩的影响是否有显著差异，同时控制学生的初始水平，避免学生初始水平的不同对比较结果产生影响。
- MANCOVA（Multivariate Analysis of Covariance）：多元协方差分析，同时控制多个协变量，比较两个或多个组的多个相关因变量是否有显著差异，适用于有多个相关因变量和多个协变量的情况。例如，用于比较不同教学方法对学生成绩、学生态度和学生动机等多个方面的影响是否有显著差异，同时控制学生的初始水平、性别、年龄等因素的影响。
</details>

👉🏻[Click to enter the ENV222 exercise section](../ENV222 exercise/ENV222 exercise.html)<br>
👉🏻[Click to enter the ENV221 note section](../ENV221 note/ENV221 note.html)

# <span style="color:gray; font-family:Microsoft JhengHei;">**1**</span> **R-markdown**<span style="font-size: 15px;">~(HTML)~</span> **syntax** 

## <span style="color:gray; font-family:Microsoft JhengHei;">**1.1**</span> **Fundamental**

-   Subscript by Rmarkdown: Use `PM~2.5~` to form PM~2.5~. <br>Subscript by html: `log<sub>2</sub>` will be displayed as log<sub>2</sub>.<br>

-   Superscript by Rmarkdown: Use `R^2^` to form R^2^. <br>Superscript by html: `2<sup>n</sup>` will be displayed as 2<sup>n</sup>.<br>

-   Use `$E = mc^2$` to form $E = mc^2$<br>

-   Use `[Link of XJTLU](http://xjtlu.edu.cn)` to form [Link of XJTLU](https://www.xjtlu.edu.cn/en/)<br>

-   Use `<mark>text</mark>` to highlight the <mark>text</mark>

-   Use `<u>text</u>` to add underline to the <u>text</u>

-   Use `<center><img src="images/rstudio-qmd-how-it-works.png" width="1400" height="257"/>` or `<center> ![rstudio qmd how it works](images/rstudio-qmd-how-it-works.png){width=100%}` to form<br><center>![Rstudio qmd how it works](images/rstudio-qmd-how-it-works.png){width="100%"}</center><br>

-   Use `<iframe src="https://www.r-project.org/" width="100%" height="300px"></iframe>` to form a windows which show another file on-line, like this:<iframe src="https://www.r-project.org/" width="100%" height="300px"></iframe>

-   Use the following HTML code to add a video to your Rmarkdown(HTML):
```{html, eval=FALSE}
<video width="420" controls>
  <source src="mov_bbb.mp4" type="video/mp4">
  <source src="mov_bbb.ogg" type="video/ogg">
 Your browser does not support the video tag.
</video>
```

-   Use something like `{r, fig.width = 6, fig.height = 4, fig.align='center'}` in front of the code chunk to change the output graphics

-   Also, use`{r, XXX-Plot, fig.cap="XXX-Plot"}` in the front of code chunk to add a caption of this figure

-   Use something like`<span style="color:red; font-weight:bold; font-size:16px; font-family:Tahoma;">sentence</span>` to change the properties of text

-   Use the following HTML code to add a foldable item to your Rmarkdown(HTML): 
```{html, eval=FALSE}
<details>
  <summary>title</summary>
  content
</details>
```
<details><summary>title</summary>content</details>

-   Use<br> `| Name | Math | English |`<br> `|:----:|:-----|--------:|`<br> `| Tom  | 93   |     100 |`<br> `| Mary | 60   |      90 |`<br> to form<br>

| Name | Math | English |
|:----:|:-----|--------:|
| Tom  | 93   |     100 |
| Mary | 60   |      90 |

-   Or use

```{r echo=TRUE}
library(knitr)
df <- data.frame(
  Math = c(80, 90),
  English = c(85, 95),
  row.names = c("Tom", "Mary")
)
kable(df, format = "markdown")
```

-   Use

```         
- 1. 
- 2. 
    - 1.
    - 2.
- 3.
```

to form sub-rank like this below:<br>

-   

    1.  

-   

    2.  

    -   

        1.  

    -   

        2.  

-   

    3.  

## <span style="color:gray; font-family:Microsoft JhengHei;">**1.2**</span> **Advanced**

-   Numbering, caption, and cross-reference of R-plots in academic paper [Click to see the detail in ENV222 Week5-5.2](https://pzhao.org/openr/R-graphs-advanced.html#numbering-caption-and-cross-reference)

# <span style="color:gray; font-family:Microsoft JhengHei;">**2**</span> **Basic R charaters**

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.1**</span> **Check the data type**

```{r echo=TRUE}
# import dataset
x <- 'The world is on the verge of being flipped topsy-turvy.'
dtf <- read.csv('data/student_names.csv')
head(dtf)
# data type
class(x)
# length of the dataset
length(x)
# length of the sub dataset
nchar(x)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.2**</span> **Index to maximum and minimum values**

-   Find the longest name in [*student_names.csv*]{style="color:green"}, `which.max` or `which.min` is used to find the index of the (first) minimum or maximum of a numeric (or logical) vector

```{r echo=TRUE}
name_n <- nchar(dtf$Name)
name_nmax <- which.max(name_n)
dtf$Name[name_nmax]
# or
dtf$Name[which.max(nchar((dtf$Name)))]
# or
library(magrittr)
dtf$Name %>% nchar() %>% which.max() %>% dtf$Name[.]
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.3**</span> **Capital and small letter**

```{r echo=TRUE}
# tolower() toupper()
(xupper <- toupper(x))
(dtf$pro <- tolower(dtf$Prgrm))
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.4**</span> **Split string**

```{r echo=TRUE}
# strsplit()
x_word <- strsplit(xupper, ' ')
class(x_word)
# If you want to extract the first element in the list, you need to use double brackets [[]], and if you want to extract the first sublist in the list, use single brackets []
x_word1 <- x_word[[1]]
class(x_word1)
table(x_word1)  # Form a table which involved the frequency of each char acter
x_word1[!duplicated(x_word1)]  # Find the distinct characters in the list by use duplicated() function
unique(x_word1)  # Other way yo detect the distinct characters
lapply(x_word, length)  # The output of the lapply() function is a list
sapply(x_word, length)  # The output of the sapply() function is a vector or a matrix
sapply(x_word, nchar)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.5**</span> **Separate column**

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# separate() is a function in the tidyr package that can be used to split a column in a data box into multiple columns
library(tidyr)
dtf2 <- separate(dtf, Name, c("GivenName", "LastName"), sep = ' ')  # separate(data, col, into, sep)
dtf$FamilyName <- dtf2$LastName
head(dtf)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.6**</span> **Extract**

The world is [on]{style="color:red"} the verge of being flipped topsy-turvy.

```{r echo=TRUE}
# substr() is a built-in function in R that can be used to extract or replace substrings from a character vector
substr(x, 13, 15)  # substr(x, start, stop)
dtf$NameAbb <- substr(dtf$Name, 1, 1)
head(dtf, 3)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.7**</span> **Connect**

```{r echo=TRUE}
# paste() function can convert multiple objects into character vectors and concatenate them
paste(x, '<end>', sep = ' ')  # paste(x1, x2,... sep, collapse)
paste(dtf$NameAbb, '.', sep = '')
paste(dtf$NameAbb, collapse = ' ')  # collapse = ' ' put all of the characters into a character
paste(dtf$NameAbb, dtf$FamilyName, sep = '. ')[7]  # This is my name for academic essay cite
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.8**</span> **Find**

```{r echo=TRUE}
# grep() function in R is a built-in function that searches for a pattern match in each element of character 
y <- c("R", "Python", "Java")
grep("Java", y)
for(i in 1:length(y)) {
  print(grep(as.character(y[i]), y))
}
sapply(y, function(x) grep(x, y))

head(table(dtf2$GivenName), 12)
grep('Jiayi', dtf$Name, value = TRUE)
grep('Jiayi|Guo', dtf$Name, value = TRUE)

# regexpr() function is used to identify the position of the pattern in the character vector, where each element is searched separately.
z <- c("R is fun", "R is cool", "R is awesome")
regexpr("is", z)  # Returns include starting position, duration length, data type ...
gregexpr("is", z)  # The gregexpr() function returns all matching positions and lengths, as a list
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.9**</span> **Replace**

```{r echo=TRUE}
# gsub()
gsub(' ', '-', x)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**2.10**</span> **[Regular expression]{style="color:orange"}**

```{r echo=TRUE}
# help(regex)
# Find the one who has a given name with 4 letters and a family name with 4 letters
grep('^[[:alpha:]]{4} [[:alpha:]]{4}$', dtf$Name, value = TRUE)

# Here, parentheses are used to create a capturing group. A capturing group is a subexpression of a regular expression that can capture and store the matched text during matching. 
# In this example, the capturing group is used to extract the first word from the string. Without a capturing group, the entire matched string would be replaced with \\1 instead of just the first word.
dtf$FirstName <- gsub('^([^ ]+).+[^ ]+$', '\\1', dtf$Name)
head(dtf)
```

```{r eval=FALSE}
Rmarkdown 中正则表达式的基本语法如下：
  . 匹配任意单个字符，除了换行符。
  [ ] 匹配方括号内的任意一个字符，例如 [abc] 匹配 a 或 b 或 c。
  [^ ] 匹配方括号外的任意一个字符，例如 [^abc] 匹配除了 a 和 b 和 c 之外的任意字符。
  - 在方括号内表示范围，例如 [a-z] 匹配小写字母， [0-9] 匹配数字。
  \d \D \w \W \s \S 分别匹配数字、非数字、单词字符（字母、数字和下划线）、非单词字符、空白符（空格、制表符和换行符）、非空白符。
  \b \B ^ $ \ 分别匹配单词边界（单词和非单词之间）、非单词边界（两个单词或两个非单词之间）、字符串开头、字符串结尾、转义符（用于匹配元字符本身）。
  ( ) | ? + * { } \ 分别匹配分组或捕获子表达式（可以用反斜杠加数字引用），选择（匹配左边或右边），零次或一次重复，一次或多次重复，零次或多次重复，指定重复次数，零宽断言（匹配位置而不是字符）。
简单的例子，查找 Markdown 链接（[This is a link](https://www.example.com)）：
\[([^\]]+)\]\(([^)]+)\)
这个正则表达式可以分解为以下部分：
  \[ 匹配左方括号
  ([^\]]+) 匹配并捕获一个或多个不是右方括号的字符
  \] 匹配右方括号
  \( 匹配左圆括号
  ([^)]+) 匹配并捕获一个或多个不是右圆括号的字符
  \) 匹配右圆括号
```

# <span style="color:gray; font-family:Microsoft JhengHei;">**3**</span> **Time data in R**

## <span style="color:gray; font-family:Microsoft JhengHei;">**3.1**</span> **Format of time**

```{r echo=TRUE}
# Check the current date
date()
# character
d1 <- "2/11/1962"
# Date/Time format, we can just directly use like "d2 + 1" to add 1 day to d2
d2 <- Sys.Date()
t2 <- Sys.time()
# Check their type
t(list(class(d1), class(d2), class(t2)))
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**3.2**</span> **Numeric of date**

```{r echo=TRUE}
# Use format="" to identify the character to date
d3 <- as.Date("2/11/1962", format="%d/%m/%Y" )
as.numeric(d3)
d3 + 2617
format(d3, '%Y %m %d')
format(d3, "%Y %B %d %A")
# Different format will have different meaning
d4 <- as.Date( "2/11/1962", format="%m/%d/%Y" )
d3 == d4
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**3.2.1**</span> **Time format codes**

`%Y`: Four-digit year<br> `%y`: Two-digit year<br> `%m`: Two-digit month (01\~12)<br> `%d`: Two-digit day of the month (01\~31)<br> `%H`: Hour in 24-hour format (00\~23)<br> `%M`: Two-digit minute (00\~59)<br> `%S`: Two-digit second (00\~59)<br> `%z`: Time zone offset, for example +0800<br> `%Z`: Time zone name, for example CST

## <span style="color:gray; font-family:Microsoft JhengHei;">**3.3**</span> **Calculating date**

```{r echo=TRUE}
# import built-in data diet (The data concern a subsample of subjects drawn from larger cohort studies of the incidence of coronary heart disease (CHD))
library('Epi')
data("diet")
str(diet)
# Prepare data which we will deal with
bdat <- diet$dox[1]
bdat
# Some basic calculation between dates
bdat + 1

diet$dox2 <- format(diet$dox, format="%A %d %B %Y")
head(diet$dox2, 3)

# Some advanced calculation between dates
max(diet$dox)
range(diet$dox)
mean(diet$dox)
median(diet$dox)
diff(range(diet$dox))
difftime(min(diet$dox), max(diet$dox), units = "weeks")  # Set unit

# Epi::cal.yr() function converts the date format to numeric format
diet2 <- Epi::cal.yr(diet)
str(diet2)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**3.4**</span> **Set time zone & calculation**

```{r echo=TRUE}
bd <- '1994-09-22 20:30:00'
class(bd)
bdtime <- strptime(x = bd, format = '%Y-%m-%d %H:%M:%S', tz = "Asia/Shanghai")  # Set character to time format and add a time zone
class(bdtime)
t(unclass(bdtime))
bdtime$wday
format(bdtime, format = '%d.%m.%Y')
bdtime + 1
# Also, some essential calculation
bd2 <- '1995-09-01 7:30:00'
bdtime2 <- strptime(bd2, format = '%Y-%m-%d %H:%M:%S', tz = 'Asia/Shanghai')
bdtime2 - bdtime
difftime(time1 = bdtime2, time2 = bdtime, units = 'secs')  # Set unit
mean(c(bdtime, bdtime2))
```

# <span style="color:gray; font-family:Microsoft JhengHei;">**4**</span> **[LaTeX]{style="color:orange"}**

## <span style="color:gray; font-family:Microsoft JhengHei;">**4.1**</span> **Fundamental**

<center><img src="images/Mathematical Annotation in R.png" width="600" height="579"/></center>

-   Use `$$e^{i\pi}+1=0$$` to form Euler's Law expression $$e^{i\pi}+1=0$$
-   [Hyperlink of a CN website for more detail about LaTeX](https://blog.csdn.net/ViatorSun/article/details/82826664)

## <span style="color:gray; font-family:Microsoft JhengHei;">**4.2**</span> **Advanced**

-   Here are some additional formulas from ENV221 statistic method:<br>
    1.  [Z-test]{style="color:orange"}:<br> The LaTex expression for Z-test is: $$Z=\frac{\overline{x}-\mu}{\frac{\sigma}{\sqrt{n}}}$$ where $\overline{x}$ is the sample mean, $\mu$ is the population mean, $\sigma$ is the population standard deviation, and $n$ is the sample size.
    2.  [t-test]{style="color:orange"}:<br> The LaTex expression for t-test is: $$t=\frac{\overline{x}-\mu}{\frac{s}{\sqrt{n}}}$$ where $\overline{x}$ is the sample mean, $\mu$ is the population mean, $s$ is the sample standard deviation, and $n$ is the sample size.
    3.  [F-test]{style="color:orange"}:<br> The LaTex expression for F-test is: $$F=\frac{s_1^2}{s_2^2}$$ where $s_1^2$ is the variance of the first sample and $s_2^2$ is the variance of the second sample.
    4.  [Chi-square test]{style="color:orange"}:<br> The LaTex expression for the chi-square test is: $$\chi2=\sum_{i=1}{n}\frac{(O_i-E_i)^2}{E_i}$$ where $O_i$ represents observed values and $E_i$ represents expected values.

# <span style="color:gray; font-family:Microsoft JhengHei;">**5**</span> **R graph (advanced)**

## <span style="color:gray; font-family:Microsoft JhengHei;">**5.1**</span> **Different theme of plot**

```{r, fig.align='center'}
library(ggplot2)
bw <- ggplot(CO2) + geom_point(aes(conc, uptake)) + theme_bw()
test <- ggplot(CO2) + geom_point(aes(conc, uptake)) + theme_test()
classic <- ggplot(CO2) + geom_point(aes(conc, uptake)) + theme_classic()
library(patchwork)
bw + test + classic + 
  plot_layout(ncol = 3, widths = c(1, 1, 1), heights = c(1, 1, 1)) + 
  plot_annotation(
    title = expression(CO[2] * " uptake by plant type plot with different theme"),
    tag_levels = "A"
  )
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**5.2**</span> **Math formulas with R**

```{r, fig.width = 8, fig.height = 4, fig.align='center'}
head(CO2)
# fundamental expression
plot(CO2$conc, CO2$uptake, pch = 16, las = 1, 
     xlab = 'CO2 concentration', ylab = 'CO2 uptake')
# Advanced expression (Use `?plotmath` to check more details of mathematical annotation in R)
plot(CO2$conc, CO2$uptake, pch = 16, las = 1, 
     xlab = expression('CO'[2] * ' concentration (mL/L)'), 
     ylab = expression('CO'[2] * ' uptake (' *mu * 'mol m'^-2 * 's'^-1 * ')'))
# LaTeX expression
library(latex2exp)
plot(CO2$conc, CO2$uptake, pch = 16, las = 1, 
     xlab = TeX('CO$_2$ concentration (mL/L)'), 
     ylab = TeX('CO$_2$ uptake ($\\mu$mol m$^{-2}$ s$^{-1}$)'))
text(850, 30, expression(prod(plain(P)(X == x), x)))
```

-   [Hyperlink of a CN website for more detail about Mathematical Annotation in R](https://www.cnblogs.com/kisen/p/12574830.html)

## <span style="color:gray; font-family:Microsoft JhengHei;">**5.3**</span> **Size and layout**

-   ggplot2: patchwork package is used to range the size and layout of multiply plots

```{r, fig.width = 8, fig.height = 5, fig.align='center', warning=FALSE}
library(patchwork)
p1 <- ggplot(airquality) + geom_boxplot(aes(as.factor(Month), Ozone))
p2 <- ggplot(airquality) + geom_point(aes(Solar.R, Ozone))
p3 <- ggplot(airquality) + geom_histogram(aes(Ozone))
p1 + p2 + p3
p1 + p2 / p3
(p1 + p2) / p3
(p1 + p2) / p3 + plot_annotation(tag_levels = 'A') + 
  plot_layout(ncol = 2, widths = c(1, 1), heights = c(1, 1))  # plot_layout() function is used to define the grid layout of the composite graph.
```

-   Built-in par() function

```{r}
par(mfrow = c(2, 3))  # Set the layout by using vector c(x, y)
plot(airquality$Solar.R, airquality$Ozone)
hist(airquality$Solar.R)
barplot(airquality$Month)
plot(airquality$Solar.R, airquality$Ozone)
hist(airquality$Solar.R)
barplot(airquality$Month)
```

-   <span style="color:red">Built-in layout() function</span>

```{r, fig.width = 8, fig.height = 5, fig.align='center'}
# Use a matrix to store the information about layout
mymat <- matrix(1:6, nrow = 2)
layout(mymat)
plot(airquality$Solar.R, airquality$Ozone)
hist(airquality$Solar.R)
barplot(airquality$Month)
plot(airquality$Solar.R, airquality$Ozone)
hist(airquality$Solar.R)
barplot(airquality$Month)
# Also, customize the exact layout by using some parameters like 'widths=' and 'heights=' by filling vector
mymat <- matrix(c(1, 1:5), nrow = 2)
mymat  # Check the matrix which was used to layout plots
layout(mymat, widths = c(1, 1, 2), heights = c(1, 2))
plot(airquality$Solar.R, airquality$Ozone)
hist(airquality$Solar.R)
barplot(airquality$Month)
plot(airquality$Solar.R, airquality$Ozone)
hist(airquality$Solar.R)
# This is an example from quiz1. Also, please check the exercises to view more difficult questions
mymat <- matrix(c(1, 2, 3, 0), nrow = 2)
mymat  # Check the matrix which was used to layout plots
layout(mymat, widths = c(4, 1), heights = c(2, 1))  # Set the ratio between widths and heights
plot(iris$Sepal.Length, iris$Sepal.Width, pch=20, xlab='Sepal Length (cm)', ylab='Sepal Width (cm)', las=1)
boxplot(iris$Sepal.Length, pch=20, las=1, horizontal=T)
boxplot(iris$Sepal.Width, pch=20, las=2)
```

# <span style="color:gray; font-family:Microsoft JhengHei;">**6**</span> **R Tidyverse**

## <span style="color:gray; font-family:Microsoft JhengHei;">**6.1**</span> **Workflow**

<center>![Tidyverse workflow](images/Tidyverse workflow.png){width=75%}</center>

## <span style="color:gray; font-family:Microsoft JhengHei;">**6.2**</span> **Fundamental operations**
```{r, message=FALSE}
# Load the package
library(tidyverse)
# Check the members of them
tidyverse_packages()
```
Core members and their function:

- `ggplot2`: Creating graphics
- `dplyr`: Data manipulation
- `tidyr`: Get to tidy data
- `readr`: Read rectangular data
- `purrr`: Functional programming
- `tibble`: Re-imagining of the data frame
- `stringr`: Working with strings
- `forcats`: Working with factors

## <span style="color:gray; font-family:Microsoft JhengHei;">**6.3**</span> **Pipe operator**

The pipe operator can be written as `%>%` or `|>`
```{r}
x <- c(0.109, 0.359, 0.63, 0.996, 0.515, 0.142, 0.017, 0.829, 0.907)
# Method 1:
y1 <- log(x)
y2 <- diff(y1)
y3 <- exp(y2)
z <- round(y3)
# Method 2
z <- round(exp(diff(log(x))))
# Pipe method
z <- x %>% log() %>% diff() %>% exp() %>% round()
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**6.4**</span> **Mutiply work by using tidyverse pipe**

### <span style="color:gray; font-family:Microsoft JhengHei;">**6.4.1**</span> **Graph work**
```{r, fig.align='center'}
# By using R built-in par() function and a loop
par(mfrow = c(2, 2))
for (i in 1:4) {
  boxplot(iris[, i] ~ iris$Species, las = 1, xlab = 'Species', ylab = names(iris)[i])
}
# By using pivot_longer() function and tidyverse pipe
iris |> pivot_longer(-Species) |> ggplot() + geom_boxplot(aes(Species, value)) + facet_wrap(name ~.)
```
### <span style="color:gray; font-family:Microsoft JhengHei;">**6.4.2**</span> **Statistic work**
```{r}
# base R
dtf1_mean <- data.frame(Species = unique(iris$Species), Mean_Sepal_Length = tapply(iris$Sepal.Length, iris$Species, mean, na.rm = TRUE))
dtf1_sd <- data.frame(Species = unique(iris$Species), SD_Sepal_Length = tapply(iris$Sepal.Length, iris$Species, sd, na.rm = TRUE))
dtf1_median <- data.frame(Species = unique(iris$Species), Median_Sepal_Length = tapply(iris$Sepal.Length, iris$Species, median, na.rm = TRUE))
names(dtf1_mean) <- c("Species", "Mean_Sepal_Length")
names(dtf1_sd) <- c("Species", "SD_Sepal_Length")
names(dtf1_median) <- c("Species", "Median_Sepal_Length")
cbind(dtf1_mean, dtf1_sd, dtf1_median)  # Show them in one table
# use a loop
dtf <- data.frame(rep(NA, 3))
for (i in 1:4) {
  dtf1_mean <- data.frame(tapply(iris[, i], iris$Species, mean, na.rm = TRUE))
  dtf1_sd <- data.frame(tapply(iris[, i], iris$Species, sd, na.rm = TRUE))
  dtf1_median <- data.frame(tapply(iris[, i], iris$Species, median, na.rm = TRUE))
  dtf1 <- cbind(dtf1_mean, dtf1_sd, dtf1_median)
  names(dtf1) <- paste0(names(iris)[i], '.', c('mean', 'sd', 'median'))
  dtf <- cbind(dtf, dtf1)
}
dtf
# tidyverse
dtf <- iris |> 
  pivot_longer(-Species) |> 
  group_by(Species, name) |> 
  summarise(mean = mean(value, na.rm = TRUE),
            sd   = sd(value, na.rm = TRUE),
            median = median(value, na.rm = TRUE),
            .groups = "drop")

dtf
```



## <span style="color:gray; font-family:Microsoft JhengHei;">**6.5**</span> **Tidy the dataset**

```{r}
# Original dataset of table1
table1
# Compute rate per 10,000
table1 %>% mutate(rate = cases / population * 10000)
# Compute cases per year
table1 %>% count(year, wt = cases)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**6.6**</span> **Conversions the dataframe type**

```{r}
# Original dataset of table2
table2
# Divided the type into cases and population
table2 %>% pivot_wider(names_from = type, values_from = count)
# Original dataset of table3
table3
# Separate the rate into cases and population
table3 %>% separate(col = rate, into = c("cases", "population"), sep = "/")
# Original dataset of table4a and table4b
cbind(table4a, table4b)
# Put table4a and table4b together to form a new table with both of their dataset
tidy4a_changed <- table4a %>% pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")
tidy4b_changed <- table4b %>% pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "population")
left_join(tidy4a_changed, tidy4b_changed)   ## Kind of like MySQL
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**6.7**</span> **Find missing observations**

```{r}
library(openair)
library(tidyverse)
# create a function to count missing observations
sum_of_na <- function(x){
  sum(is.na(x))
}
mydata %>% summarise(
  across(everything(), sum_of_na)
)
```

# <span style="color:gray; font-family:Microsoft JhengHei;">**7**</span> **ANOVA (Post-hoc tests)**

## <span style="color:gray; font-family:Microsoft JhengHei;">**7.1**</span> **Post-hoc tests**

Background informations: A biologist studies the weight gain of male lab rats on diets over a 4-week period. Three different diets are applied.

```{r}
# Statistic anlysis
(dtf <- data.frame(diet1 = c(90, 95, 100),
                   diet2 = c(120, 125, 130),
                   diet3 = c(125, 130, 135)))
dtf2 <- stack(dtf)
names(dtf2) <- c("wg", "diet")
wg_aov <- aov(wg ~ diet, data = dtf2)
summary(wg_aov)
```

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
# Visualization
library(ggplot2)
ggplot(dtf2) + geom_boxplot(aes(wg, diet))
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**7.2**</span> **Fisher’s Least Significant Difference (LSD) Test**

### <span style="color:gray; font-family:Microsoft JhengHei;">**7.2.1**</span> **Concept**

Pair-wise comparisons of all the groups based on the $t$-test:
$$L S D=t_{\alpha / 2} \sqrt{S_{p}^{2}\left(\frac{1}{n_1}+\frac{1}{n_2}+\cdots\right)}$$
$$S_{p}^{2}=\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}+\left(n_{3}-1\right) S_{3}^{2}+\cdots}{\left(n_{1}-1\right)+\left(n_{2}-1\right)+\left(n_{3}-1\right)+\cdots}$$

- $S_{p}^{2}:$: pooled standard deviation (some use Mean Standard Error)
- $t_{\alpha / 2}: \mathrm{t}$: $t$ critical value at $\alpha=0.025$
- Degree of freedom: $N - k$
    - $N$: total observations
    - $k$: number of factors
- If $\left|\bar{x}_{1}-\bar{x}_{2}\right|>L S D$, then the difference of $x_1$ group and $x_2$ group is significant at $\alpha$.
- In multiple comparisons ($k$ factors), the number of comparison needed is: $\frac{k(k-1)}{2}$

### <span style="color:gray; font-family:Microsoft JhengHei;">**7.2.2**</span> **Example**
(Rats on diets in the previous section)

1. Step by step
```{r}
# Calculate LSD
n <- nrow(dtf2)
k <- nlevels(dtf2$diet)
dfree <- n - k
t_critical <- qt(0.05/2, df = dfree, lower.tail = FALSE)
sp2 <- sum((3 - 1) * apply(dtf, 2, sd) ^ 2)/ dfree
LSD <- t_critical * sqrt(sp2 * (1/3 + 1/3 + 1/3))
# Calculate |mean_x1-mean_x2|
dtf_groupmean <- colMeans(dtf)
paired_groupmean <- combn(dtf_groupmean, 2)
paired_groupmean[2, ] - paired_groupmean[1, ]
```
2. Step by step by using loop
```{r}
library(dplyr)
dtf_sm <- dtf2 |> 
  group_by(diet) |> 
  summarise(n = length(wg), sd = sd(wg), mean = mean(wg))
sp2 <- sum((dtf_sm$n - 1) * dtf_sm$sd ^ 2 )/ dfree
LSD <- t_critical * sqrt(sp2 * sum(1 / dtf_sm$n))
paired_groupmean <- combn(dtf_sm$mean, 2)
paired_groupmean[2, ] - paired_groupmean[1, ]
```
3. One step
```{r}
library(agricolae)
# Statistic analysis
LSD.test(wg_aov, "diet", p.adj = "bonferroni") |> print()
```
<details>
  <summary>The meaning of each parameter in this table</summary>
- $statistics：包含ANOVA分析的统计量（statistics）的列表。
   - MSerror：平均方差误差（mean square error），也称为残差方差，表示模型误差的平均程度。
   - Df：自由度（degrees of freedom）。
   - Mean：均值（mean）。
   - CV：变异系数（coefficient of variation），变异系数越大，说明数据的离散程度越大。
   - t.value：t值（t-value），表示组间均值之间的显著性差异程度。
   - MSD：最小显著差异（minimum significant difference），表示在显著性水平下两个组之间的最小显著差异值。
- $parameters：包含对比分析的参数（parameters）的列表。
   - test：所使用的多重比较方法（multiple comparison method），此处为Fisher-LSD法。
   - p.ajusted：经过校正后的显著性水平（adjusted significance level），此处为Bonferroni法。
   -name.t：所进行对比分析的因素名称（name of tested factor），此处为diet。
   - ntr：因素水平数（number of treatments），此处为3。
   - alpha：显著性水平（significance level），此处为0.05。
- $means：包含各组均值和统计信息（means and statistics）的列表。
   - wg：组均值（group mean）。
   - std：标准差（standard deviation）。
   - r：重复次数（replications）。
   - LCL：下限置信区间（lower confidence limit）。
   - UCL：上限置信区间（upper confidence limit）。
   - Min：最小值（minimum value）。
   - Max：最大值（maximum value）。
   - Q25：25%分位数（25th percentile）。
   - Q50：50%分位数（50th percentile），也称为中位数。
   - Q75：75%分位数（75th percentile）。
- $comparison：对比分析结果（comparison），此处为空。
- $groups：分组结果（groups）。
   - wg：组均值（group mean）。
   - groups：分组结果（groups），使用字母表示不同组别，相同字母表示在统计上没有显著差异。
- attr(,"class")：结果的类别（class），此处为"group"。
</details>
```{r, fig.width = 6, fig.height = 4, fig.align='center'}
# Visualization
LSD.test(wg_aov, "diet", p.adj = "bonferroni") |> plot()
box()
```
Conclusion: At $\alpha = 0.05$, Diet 2 and Diet 3 are significantly different from Diet 1 in the mean weight gain, while Diet 2 is not significantly different from Diet 3.

## <span style="color:gray; font-family:Microsoft JhengHei;">**7.3**</span> **Bonferroni t-test**

### <span style="color:gray; font-family:Microsoft JhengHei;">**7.3.1**</span> **Concept**

A multiple-comparison post-hoc test, which sets the significance cut off at $\alpha/m$ for each comparison, where $m$ represents [the <u>number</u> of comparisons we apply]{style="color:red"}.

[Overall chance of making a Type I error:]{style="color:#880000"}
```{r}
m <- 1:100
siglevel <- 0.05
Type_I <- 1 - (1 - (siglevel / m)) ^ m
Type_I
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**7.3.2**</span> **Example**
(Rats on diets in the previous section)

1. Step by step
```{r}
m <- choose(nlevels(dtf2$diet), 2)  # 1:2 or 1:3 or 2:3
alpha_cor <- 0.05 / m
```
```{r}
# Pairwise comparison between diet1 and diet2
t.test(wg ~ diet, dtf2, subset = diet %in% c("diet1", "diet2"), conf.level = 1 - alpha_cor)
# Pairwise comparison between diet1 and diet3
t.test(wg ~ diet, dtf2, subset = diet %in% c("diet1", "diet3"), conf.level = 1 - alpha_cor)
# Pairwise comparison between diet2 and diet3
t.test(wg ~ diet, dtf2, subset = diet %in% c("diet2", "diet3"), conf.level = 1 - alpha_cor)
```
2. One step
```{r}
(diet_pt <- pairwise.t.test(dtf2$wg, dtf2$diet, pool.sd = FALSE,var.equal = TRUE, p.adj = "none"))
diet_pt$p.value < 0.05
```
Conclusion: At $\alpha = 0.05$, Diet 2 and Diet 3 are significantly different from Diet 1 in the mean weight gain, while Diet 2 is not significantly different from Diet 3.

# <span style="color:gray; font-family:Microsoft JhengHei;">**8**</span> **MANOVA**
<center>![One-Way ANOVA (ENV221)](images/One-Way ANOVA.jpg)</center>
<center>![Two-Way ANOVA (ENV221)](images/Two-Way ANOVA.jpg)</center>
<center>[The Differences Between ANOVA, ANCOVA, MANOVA, and MANCOVA](https://www.statology.org/differences-between-anova-ancova-manova-mancova/)</center>

## <span style="color:gray; font-family:Microsoft JhengHei;">**8.1**</span> **Definition of MANOVA**

**Univariate Analysis of Variance (ANOVA):**

- one dependent variable (continuous) ~ one or multiple independent variables (categorical).  
**Multivariate Analysis of Variance (MANOVA)**
- multiple dependent variables (continuous) ~ one or multiple independent variables (categorical).  
Comparing multivariate sample means. It uses the covariance between outcome variables in testing the statistical significance of the mean differences when there are multiple dependent variables.  

Merit of MANOVA:

1. Reduce the Type I error
2. It allows for the analysis of multiple dependent variables simultaneously
3. It provides information about the strength and direction of relationships

## <span style="color:gray; font-family:Microsoft JhengHei;">**8.2**</span> **Coding and visualization**

**Example:** Influence of <u>teaching methods</u> on student <u>satisfaction scores</u> and <u>exam scores</u>.
```{r, fig.width = 6, fig.height = 4, fig.align='center', message=FALSE}
dtf <- read.csv('data/teaching_methods.csv')
head(dtf, 3)
# ANOVA between Test and Method
summary(aov(Test ~ Method, data = dtf))
# ANOVA between Satisfaction and Method
summary(aov(Satisfaction ~ Method, data = dtf))
# Visualization with Scatter plot
library(ggplot2)
library(tidyr)
dtf |> pivot_longer(-Method) |> 
  ggplot() + 
  geom_dotplot(aes(x = Method, y = value, group = Method), binaxis = "y", stackdir = "center") + 
  facet_wrap(name~.)
# Visualization with Box plot
par(mfrow = c(1, 3))
boxplot(Test ~ Method, data = dtf)
boxplot(Satisfaction ~ Method, data = dtf)
plot(dtf$Satisfaction, dtf$Test, col = dtf$Method, pch = 16, xlab = 'Satisfaction', ylab = 'Test')
# MANOVA method: use manova() function with multiple response variables ~ one or multiple factor
# column bind way
tm_manova <- manova(cbind(dtf$Test, dtf$Satisfaction) ~ dtf$Method)
# matrix way
tm_manova <- manova(as.matrix(dtf[, c('Test', 'Satisfaction')]) ~ dtf$Method)
summary(tm_manova)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**8.3**</span> **One-way MANOVA**

<center>![One-way MANOVA](images/One-way MANOVA.jpg)</center>
**Example:** The iris dataset. Do the species have influence on the sepal size?
```{r, fig.align='center', message=FALSE}
# Visualization
library(ggplot2)
library(tidyr)
iris[, c('Species', 'Sepal.Length', 'Sepal.Width')] |> 
  pivot_longer(cols = c(Sepal.Length, Sepal.Width)) |> 
  ggplot() +
  geom_boxplot(aes(Species, value, fill = name)) +
  labs(y = 'Size (cm)', fill = '')
library(gplots)
par(mfrow = c(1, 2))
plotmeans(iris$Sepal.Length ~ iris$Species, xlab = "Species", ylab = "Sepal length")
plotmeans(iris$Sepal.Width ~ iris$Species, xlab = "Species", ylab = "Sepal width")
```
**Hypothesis:** multivariate normality test

- $H_0$: The population means of the sepal length and the sepal width are not different across the species.

```{r}
# Summary MANOVA result with different test method
SepalSize <- cbind(iris$Sepal.Length, iris$Sepal.Width)
iris_manova <- manova(SepalSize ~ iris$Species)
summary(iris_manova, test = 'Pillai')  # default
summary(iris_manova, test = 'Wilks')
summary(iris_manova, test = 'Roy')
summary(iris_manova, test = 'Hotelling-Lawley')
# Univariate ANOVAs for each dependent variable
summary.aov(iris_manova)
```
**Conclusion:** The species has a statistically significant effect on the sepal width and sepal length.

## <span style="color:gray; font-family:Microsoft JhengHei;">**8.4**</span> **Post-hoc test**

**Example:** after One-way MANOVA gives a significant result, which group(s) is/are different from other(s)?  
**Hypothesis:** Linear Discriminant Analysis (LDA)
```{r, fig.align='center', message=FALSE}
# Visualization
library(MASS)
iris_lda <- lda(iris$Species ~ SepalSize, CV = FALSE)
plot_lda <- data.frame(Species = iris$Species, lda = predict(iris_lda)$x)
ggplot(plot_lda) + geom_point(aes(x = lda.LD1, y = lda.LD2, colour = Species))
```
**Conclusion:** The sepal size of the setosa species is different from other species.

## <span style="color:gray; font-family:Microsoft JhengHei;">**8.5**</span> **Multivariate normality**

### <span style="color:gray; font-family:Microsoft JhengHei;">**8.5.1**</span> **Shapiro-Wilk test**

**Hypothesis:**  
$H_0$: The variable follows a normal distribution
```{r, message=FALSE}
library(rstatix)
iris |>  
  group_by(Species) |>  
  shapiro_test(Sepal.Length, Sepal.Width)
```
Tip:

- <span style="color:green">If the sample size is large (say n > 50), the visual approaches such as QQ-plot and histogram will be better for assessing the normality assumption.</span>
```{r, fig.align='center', message=FALSE}
iris[, c('Species', 'Sepal.Length', 'Sepal.Width')] |> 
  pivot_longer(cols = c(Sepal.Length, Sepal.Width)) |> 
  ggplot() +
  geom_histogram(aes(value)) +
  facet_grid(name ~ Species)
```
**Conclusion:** As $p>0.05$, the sepal length and the width for each species are normally distributed.

### <span style="color:gray; font-family:Microsoft JhengHei;">**8.5.2**</span> **Mardia’s skewness and kurtosis test**

**Hypothesis:**  
$H_0$: The variables follow a multivariate normal distribution
```{r}
library(mvnormalTest)
mardia(iris[, c('Sepal.Length', 'Sepal.Width')])$mv.test
```
Tip:

- <span style="color:green">When n > 20 for each combination of the independent and dependent variable, the multivariate normality can be assumed (Multivariate Central Limit Theorem).</span>  

**Conclusion:** As $p>0.05$, the sepal length and the width follow a multivariate normal distribution.

### <span style="color:gray; font-family:Microsoft JhengHei;">**8.5.3**</span> **Homogeneity of the variance-covariance matrix**
**Main:**  
Box’s M test: Use a lower $\alpha$ level such as $\alpha = 0.001$ to assess the $p$ value for significance.  
**Hypothesis:**  
$H_0$: The variance-covariance matrices are equal for each combination formed by each group in the independent variable.
```{r, message=FALSE}
library(biotools)
boxM(cbind(iris$Sepal.Length, iris$Sepal.Width), iris$Species)
```
**Conclusion:** As $p < 0.001$, the variance-covariance matrices for the sepal length and width are not equal for each combination formed by each species.

### <span style="color:gray; font-family:Microsoft JhengHei;">**8.5.4**</span> **Multivariate outliers**
- [MANOVA is highly sensitive to outliers and may produce Type I or II errors.]{style="color:red"}
- Multivariate outliers can be detected using the Mahalanobis Distance test. The larger the Mahalanobis Distance, the more likely it is an outlier.
```{r}
library(rstatix)
iris_outlier <- mahalanobis_distance(iris[, c('Sepal.Length', 'Sepal.Width')])
head(iris_outlier, 5)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**8.5.5**</span> **Linearity**
- Or test the regression or the slope (ENV221)
```{r}
# Visualize the pairwise scatterplot for the dependent variable for each group
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  facet_wrap(Species ~ .)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**8.5.6**</span> **Multicollinearity**
Correlation between the dependent variable.  
For three or more dependent variables, use a correlation matrix or variance inflation factor (VIF).
```{r}
# Test the correlation
cor.test(x = iris$Sepal.Length, y = iris$Sepal.Width)
# Visualization
ggplot(iris, aes(Sepal.Length, Sepal.Width)) +
  geom_point() +
  geom_smooth(method = 'lm')
```
- If $|r|$ > 0.9, there is multicollinearity.
- If r is too low, perform separate univariate ANOVA for each dependent variable.

## <span style="color:gray; font-family:Microsoft JhengHei;">**8.6**</span> **Two-way MANOVA**

<center>![Two-way MANOVA](images/Two-way MANOVA.jpg)</center>
**Example:** Plastic. Do the rate of extrusion and the additive have influence on the plastic quality?
```{r}
# Summary MANOVA result
data('Plastic', package = 'heplots')
Plastic_matrix <- as.matrix(Plastic[, c('tear','gloss','opacity')])
Plastic_manova <- manova(Plastic_matrix ~ Plastic$rate * Plastic$additive)
summary(Plastic_manova)
# Univariate ANOVAs for each dependent variable
summary.aov(Plastic_manova)
```

# <span style="color:gray; font-family:Microsoft JhengHei;">**9**</span> **ANCOVA**

## <span style="color:gray; font-family:Microsoft JhengHei;">**9.1**</span> **Definition of ANCOVA**
<span style="color:red">Test whether the independent variable(s) has a significant influence on the dependent variable, excluding the influence of the covariate (preferably highly correlated with the dependent variable)</span>
$$Y_{ij} = (\mu+\tau_{i})+\beta(x_{ij}-\bar{x})+\epsilon_{ij}$$

- $Y_{ij}$: the j-th observation under the i-th categorical group
- $\mu$: the population mean
- $i$: groups, 1,2, …
- $j$: observations, 1,2,…
- $\tau_i$: an adjustment to the y intercept for the i-th regression line
- $\mu + \tau_i$: the intercept for group i
- $\beta$: the slope of the line
- $x_{ij}$: the j-th observation of the continuous variable under the i-th group
- $\bar x$: the global mean of the variable x
- $\epsilon _{ij}$: the associated unobserved error

**Analysis of covariance (ANCOVA):**

- Dependent variable (DV): One continuous variable
- Independent variables (IVs): One or multiple categorical variables, one or multiple continuous variables (covariate, CV)

**Covariate (CV):**

- An independent variable that is not manipulated by experimenters but still influences experimental results.

**Example:**

<center>![Model simplification](images/ANCOVA-plot.png)</center>

## <span style="color:gray; font-family:Microsoft JhengHei;">**9.2**</span> **One-way ANCOVA**

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.2.1**</span> **Question**

<center>![ANCOVA](images/ANCOVA.jpg)</center>

**Example 1:** Does <u>grazing</u> have influence on the fruit production? Are grazed plants have more fruit <u>production</u> than ungrazed ones?

- Independent variable: 
   - Grazing (categorical)
- Dependent variable: 
   - Fruit production (continuous)
```{r, fig.width = 6, fig.height = 4, fig.align='center'}
df1 <- read.table("data/ipomopsis.txt", header = TRUE, stringsAsFactors = TRUE)
head(df1, 5)
tapply(df1$Fruit,df1$Grazing, mean)
library(ggplot2)
ggplot(df1) + geom_boxplot(aes(Fruit, Grazing))
# Hypothesis test
t.test(Fruit ~ Grazing, data = df1, alternative = c("greater"))
```
**Example 2:** What is the influence of <u>grazing</u> and <u>root diameter</u> on the fruit production of a plant?

Independent variables:

- grazing (categorical: grazed or ungrazed)
- root diameter (continuous, mm, covariate)

Dependent variable:

- fruit production (mg)

```{r}
# Visualization
ggplot(df1, aes(Root, Fruit))+
  geom_point() +
  geom_smooth(method = 'lm') +
  geom_point(aes(color = Grazing)) + 
  geom_smooth(aes(color = Grazing), method = 'lm')
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.2.2**</span> **Maximal model**

| Symbol | Meaning |
|:---:|:-----|
| `~` | Separating DV (<span style="color:red">left</span>) and IV (<span style="color:red">right</span>) |
| `:` | Interaction effect of two factors |
| `*` | Main effect of the two factors and the interaction effect. `f1 * f2` is equivalent to `f1 + f2 + f1:f2` |
| `^` | Square the sum of several terms. The main effect of these terms and the interaction between them |
| `.` | All variables except the DV |
```{r}
# The maximal model
df1_ancova <- lm(Fruit ~ Grazing * Root, data = df1)
summary(df1_ancova)
# The ANOVA table for the maximal model
anova(df1_ancova)
# other method to see the ANOVA table 
df1_aov <- aov(Fruit ~ Grazing * Root, data = df1)
summary(df1_aov)
summary.aov(df1_ancova)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.2.3**</span> **Minimal model**

```{r}
# Delete the interaction factor 
df1_ancova2 <- update(df1_ancova, ~ . - Grazing:Root)
summary(df1_ancova2)
# Compare the simplified model with the maximal model
anova(df1_ancova, df1_ancova2)
# Delete the grazing factor 
df1_ancova3 <- update(df1_ancova2, ~ . - Grazing)
summary(df1_ancova3)
# Compare the two models
anova(df1_ancova2, df1_ancova3)
summary(df1_ancova2)
anova(df1_ancova2)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.2.4**</span> **One step**

Criterion: Akaike’s information criterion (AIC). The model is <u>worse</u> if AIC gets <u>greater</u>.
```{r}
step(df1_ancova)
```


### <span style="color:gray; font-family:Microsoft JhengHei;">**9.2.5**</span> **Result**

```{r}
# Extracting formulas from linear regression models
equatiomatic::extract_eq(df1_ancova2, use_coefs = TRUE)
```
<a id="diagnostic statistical data text table"></a>
```{r}
# Create a diagnostic statistical data text table
stargazer::stargazer(df1_ancova2, type = 'text')
```
<details>
  <summary>The meaning of each parameter in this table</summary>
- Dependent variable: The name of the dependent variable. (因变量的名称)
- Independent variables: The names of the independent variables. (自变量的名称)
- Coefficients: Regression coefficients, indicating the degree to which an independent variable affects the dependent variable when it increases by one unit. (回归系数，表示自变量每增加一个单位对因变量的影响程度)
- Standard errors: Standard error of regression coefficients, measuring the stability of regression coefficients. (回归系数的标准误差，衡量回归系数的稳定性)
- t-statistics: t-value of regression coefficients, representing whether a regression coefficient is significantly different from zero and has a significant impact on the dependent variable. (回归系数的t值，代表回归系数是否显著不为0，即是否对因变量有显著影响)
- p-values: Significance level of regression coefficients, usually used to determine whether a regression coefficient is significantly different from zero. The smaller the p-value, the more significant the regression coefficient is considered to be. (回归系数的显著性水平，通常用于判断回归系数是否显著不为0，p值越小，表示回归系数越显著)
- Observations: Sample size. (样本数量)
- R2: Goodness-of-fit measure that represents how much variance in explanatory variables can be explained by model. A higher value indicates better fit between model and data. (拟合优度，表示模型解释变量方差的比例，数值越高表示模型拟合程度越好)
- Adjusted R2：A modified version of R2 that takes into account number of independent variables for greater accuracy. (调整后的拟合优度，考虑到自变量的个数，比R2更准确)
- Residual standard error：Standard deviation or dispersion measure for residuals; smaller values indicate better model fit. (残差标准误，表示残差的离散程度，越小表示模型越好)
- F-statistic：Statistical test used to evaluate overall goodness-of-fit for linear models. (F统计量，用于检验模型整体拟合优度是否显著)
- df：Degrees of freedom. (自由度)
- Note:p<0.1,p<0.05,p<0.01 : When p-value is less than 0.1, 0.05 or 0.01 respectively,* , ** , *** are used as symbols indicating significance levels for corresponding regressions coefficients. (p<0.1, p<0.05, p<0.01：p值小于0.1，0.05，0.01时，分别用*，**，***表示，代表回归系数的显著性水平)
</details>

## <span style="color:gray; font-family:Microsoft JhengHei;">**9.3**</span> **Two-way ANCOVA**

<center>![ANCOVA](images/ANCOVA.jpg)</center>

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.3.1**</span> **Question**

Previous experiments have shown that both genotype and sex of an organism affect body weight gain. However, a scientist believes that after adjusting for <u>age</u>, there was no significant difference in means of <u>weight</u> gain between groups at different levels of <u>sex</u> and <u>Genotype</u>. Can experiments support this claim?

- Independent variables: 
   - genotype (categorical)
   - sex (categorical)
   - age (covariate)
- Dependent variable: 
   - Weight gain (continuous)

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.3.2**</span> **Model**

```{r}
Gain <- read.table("data/Gain.txt", header = T)
head(Gain, 3)
m1 <- lm(Weight ~ Sex * Age * Genotype, data = Gain)
summary(m1)
```
- There are no things like Age:Sex or Age:Genotype, so the slope of weight gain against age does not vary with sex or genotype
- In the final minimal adequate model, three main effects were included (Sex, Age, Genotype), so it can be considered that there are intercept differences between gender, age and genotype (intercepts vary).
- The final minimal adequate model includes three main effects (Sex, Age, Genotype), but no interaction effect. This means that the effects of these variables are independent and there is no interaction between them.

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.3.3**</span> **One step**

```{r}
m2 <- step(m1)
summary(m2)
```
From the above output, we can see the coefficients of each genotype and their corresponding significance level (in the Estimate column). It can be observed that GenotypeCloneC and GenotypeCloneE have similar effects on the dependent variable, with coefficients close to -1 and very small significance levels (p-value < 0.001). Therefore, we can combine these two factors into one factor, reducing the number of genotype levels from six to five. The same approach can be applied to B and D.
```{r}
# Check
newGenotype <- as.factor(Gain$Genotype)
levels(newGenotype)
# Change
levels(newGenotype)[c(3,5)] <- "ClonesCandE"
levels(newGenotype)[c(2,4)] <- "ClonesBandD"
levels(newGenotype)
# Liner regression & compare
m3 <- lm(Weight ~ Sex + Age + newGenotype, data = Gain)
anova(m2,m3)
```
<details>
  <summary>Analysis of RSS above</summary>
In regression models, the residual sum of squares (RSS) represents the unexplained variance in the dependent variable. In this example, the RSS for Model 1 and Model 2 are 2.7489 and 2.9938 respectively. The goal of a model is to minimize RSS because it represents how well the model fits with observed values. Generally, a smaller RSS indicates a better fit for the model. When comparing two models' fit, one can use both RSS and F-statistic. In this example, although Model 2 has a slightly larger RSS than Model 1, its P-value for F-statistic is 0.1087 which does not reach commonly used significance levels such as 0.05; therefore we cannot reject null hypothesis that Model 2 performs worse than Model 1.
</details>

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.3.4**</span> **Result**

As $p=0.1087$, there is no significant difference between the two models. Therefore, the new model uses NewGenotype (four levels) instead of Genotype (six levels).
```{r}
summary(m3)
# Extracting formulas from linear regression models
equatiomatic::extract_eq(m3, use_coefs = TRUE)
# Create a diagnostic statistical data text table
stargazer::stargazer(m3, type = 'text')
```
[The meaning of each parameter in this table](#diagnostic statistical data text table)

### <span style="color:gray; font-family:Microsoft JhengHei;">**9.3.5**</span> **Visualization**

```{r}
plot(Weight~Age,data=Gain,type="n")
colours <- c("green","red","black","blue")
lines <- c(1,2)
symbols <- c(16,17)
NewSex<-as.factor(Gain$Sex)
points(Weight~Age,data=Gain,pch=symbols[as.numeric(NewSex)],
       col=colours[as.numeric(newGenotype)])
xv <- c(1,5)
for (i in 1:2) {
  for (j in 1:4){
    a <- coef(m3)[1]+(i>1)* coef(m3)[2]+(j>1)*coef(m3)[j+2]
 
    b <- coef(m3)[3]
    yv <- a+b*xv
    lines(xv,yv,lty=lines[i],col=colours[j]) } }
```

# <span style="color:gray; font-family:Microsoft JhengHei;">**10**</span> **MANCOVA**

<center>![One-Way MANCOVA](images/One-Way MANCOVA.jpg)</center>
<center>![Two-Way MANCOVA](images/Two-Way MANCOVA.jpg)</center>
- Dependent variables: multiple continuous variables
- Independent variables: one or multiple categorical variables, one or multiple continuous variables (covariates)

## <span style="color:gray; font-family:Microsoft JhengHei;">**10.1**</span> **Definition of MANCOVA**

<span style="color:red">**Multivariate Analysis of Covariance (MANCOVA) = multivariate ANCOVA = MANOVA with covariate(s)**</span><br>
Analysis for the differences among group means for a linear combination of the dependent variables after adjusted for the covariate. Test whether the independent variable(s) has a significant influence on the dependent variables, excluding the influence of the covariate (preferably highly correlated with the dependent variable)

- Independent Random Sampling: Independence of observations from all other observations.
- Level and Measurement of the Variables: The independent variables are categorical and the dependent variables are continuous or scale variables. Covariates are continuous.
- Homogeneity of Variance: Variance between groups is equal.
- Normality: For each group, each dependent variable follows a normal distribution and any linear combination of dependent variables are normally distributed

<details>
  <summary>Brief explanation in Chinese</summary>
在MANCOVA中，我们有多个因变量（即连续或比例变量），一个或多个自变量（即分类变量），以及一个或多个协变量（即连续变量）。这些变量的测量水平应该正确，并且观察值应该是独立随机采样的。这意味着，我们要确保观察值彼此独立，不受其他变量的影响。同时，我们需要检查每个组的因变量是否都符合正态分布，并且方差应该相等。  
如果我们的数据满足这些假设，则可以使用MANCOVA来探索自变量对因变量的影响，并且通过协变量来控制一些其他影响因素的影响。MANCOVA可以更准确地确定组间差异是否真实存在，而不是基于单个因变量的分析来做出判断。 MANCOVA通常用于实验设计，研究人员想要比较多个组的平均得分，同时控制其他因素的影响。
</details>

## <span style="color:gray; font-family:Microsoft JhengHei;">**10.2**</span> **Workflow**

### <span style="color:gray; font-family:Microsoft JhengHei;">**10.2.1**</span> **Question**

**Example:** Are there differences in productivity (measured by income and hours worked) for individuals in different age groups after adjusted for the education level?  

- Dependent variables:
   - wage (continuous)
   - age (continuous)
- Independent variables:
   - education (categorical)
   - year (continuous, covariate)

### <span style="color:gray; font-family:Microsoft JhengHei;">**10.2.2**</span> **Visualization**

```{r, message=FALSE}
library(tidyverse)
library(ISLR)
library(car)
ggplot(Wage, aes(age, wage)) + geom_point(alpha = 0.3) + 
  geom_smooth(method = lm) + facet_grid(year~education)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**10.2.3**</span> **Model**

- `manova()` way
```{r}
wage_manova1 <- manova(cbind(wage, age) ~ education * year, data = Wage)
wage_manova1
summary.aov(wage_manova1)
```
<details>
  <summary>Brief explanation in Chinese</summary>
根据结果，教育和年份两个因子对 wage 有显著影响，因为它们的 P 值均小于0.05。但是，交互作用项 "education:year" 的 P 值大于0.05，表明这个交互项对 wage 没有显著影响。<br><br> 
对于年龄变量，教育和(年份≈0.05)都对其有显著影响，因为它们的 P 值小于0.05。然而，交互项 "education:year" 对 age 没有显著影响，因为其 P 值大于0.05。
</details>

- `jmv::mancova()` way
```{r}
library(jmv)
wage_manova2 <- jmv::mancova(data = Wage,
                             deps = vars(wage, age),
                             factors = education, 
                             covs = year)
wage_manova2
```
<details>
  <summary>Brief explanation in Chinese</summary>
在 Multivariate Tests 表格中，我们可以看到 education 和 year 这两个自变量的多元假设检验结果。四种统计量都显示了这两个变量的组合对因变量 wage 和 age 有显著影响（p 值 < 0.0001）。<br><br>
在 Univariate Tests 表格中，我们可以看到每个因变量 wage 和 age 的单元假设检验结果。结果显示 education 对 wage 和 age 都有显著影响（p 值 < 0.0001），而 year 只对 wage 有显著影响（p 值 = 0.0004）。值得注意的是，age 的 year 效应在 p 值为 0.0529 的边缘。Residuals 列显示了每个因变量在模型中的残差方差。<br><br>
总体来说，这个 MANCOVA 模型表明，在控制了 education 和 year 之后，wage 和 age 之间存在着相关性，并且 education 和 year 对这种关系都有显著的影响。
</details>

### <span style="color:gray; font-family:Microsoft JhengHei;">**10.2.4**</span> **Result**

- Since the interaction effect is not significant (p = 0.77 for salary and p = 0.24 for age), the slopes are parallel.
- The wage and age differ significantly among education groups (p for both wage and age are far below 0.05).
- Differences in salary also significantly (p = 0.00038) increase over time (variable year), due to some economic reasons, while differences in age don’t change (p = 0.053) much.

<details>
  <summary>Brief explanation in Chinese</summary>
- 对于交互作用效应而言，它在wage和age方面的p值分别为0.771086和0.24043，因此交互作用效应不显著。这意味着不同教育水平组之间的工资和年龄差异的斜率是平行的。
- 对于MANOVA表格中的“Multivariate Tests”部分，education组之间的差异在wage和age方面都显著(p值均远远低于0.05)。
- 对于ANOVA表格中的“Univariate Tests”部分，随时间的推移，salary方面的差异显著增加(p=0.000384)，而age方面的差异则没有显著变化(p=0.05282)。这表明时间变化是造成salary变化的一个重要原因，而不是年龄变化。
</details>

# <span style="color:gray; font-family:Microsoft JhengHei;">**11**</span> **Combining statistics**

## <span style="color:gray; font-family:Microsoft JhengHei;">**11.1**</span> **Combining means and standard errors**

**Example:** Two separate but similar experiments measuring the rate of glucose production of liver cells.<br>
*Tips: for different group experments we can't just sum them up and simply calculate the mean and standard error.*

- Experiment 1: 4.802, 3.81, 4.004, 4.467, 3.8
- Experiment 2: 5.404, 5.256, 4.145, 5.401, 5.622, 4.312
- Calculate the overall $n, \bar x, se$

**If we know the row data:**
```{r}
# Row data
x1 <- c(4.802, 3.81, 4.004, 4.467, 3.8)
x2 <- c(5.404, 5.256, 4.145, 5.401, 5.622, 4.312)
# Form a new dataframe which contains Those columns
n1 <- length(x1)
n2 <- length(x2)
dtf <- data.frame(n = c(n1, n2), mean = c(mean(x1), mean(x2)), sd = c(sd(x1), sd(x2)))
dtf$se <- dtf$sd/sqrt(dtf$n)
dtf
# Calculate the mean and standard error
x <- c(x1, x2)
x_bar <- mean(x)
n <- length(x)
se <- sd(x)/sqrt(n)
c(x_bar, se)
```

**If we don't know the row data:**
```{r}
cmean <-  sum(dtf$mean * dtf$n) / sum(dtf$n)
cse <- sqrt((sum(dtf$n * ((dtf$n - 1)* dtf$se ^ 2 + dtf$mean ^ 2)) - sum(dtf$n * dtf$mean) ^ 2/ sum(dtf$n)) / (sum(dtf$n) * (sum(dtf$n) - 1)))
c(cmean, cse)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**11.2**</span> **Mean and standard errors of sum and difference**

### <span style="color:gray; font-family:Microsoft JhengHei;">**11.2.1**</span> **Concepts**

- First we have two variables $p$ and $q$
- The third variable $x = p + q$
- The fourth variable $y = p - q$
- When $n_p \neq n_q \neq n$:
$$\bar x = \bar p + \bar q$$
$$\bar y = \bar p - \bar q$$
$$se_x = se_y = \sqrt{\frac{(n_p - 1)se_p^2 + (n_q - 1)se_q^2}{n_p + n_q - 2} \cdot \frac{n_p + n_q}{n_p n_q}}$$
- When $n_p = n_q = n$:
$$se_x = se_y = \sqrt{\frac{se_p^2 + se_q^2}{n}}$$

### <span style="color:gray; font-family:Microsoft JhengHei;">**11.2.2**</span> **Example**

A luciferase-based assay is being used to quantify the amount of ATP and ADP in small tissue samples. The amount of ATP (q) is measured directly in 8 samples as $3.25 \pm 0.14 mol g^{-1}$. A further 10 samples are treated with pyruvate kinase plus phosphoenolpyruvate to convert ADP quantitatively to ATP. The total ATP (p) in these samples is determined to be $4.56 \pm 0.29\mu mol g^{-1}$. The ADP content is $p - q$.<br><br>
What is the mean and standard error of ADP concentration?
```{r}
# Dataframe of example experiment
x <- data.frame(mean = c(3.25, 4.56), n = c(8, 10), se = c(0.14, 0.29))
x
ADP <- diff(x$mean)
cse <- sqrt(sum(x$se ^ 2 * (x$n - 1)) / (sum(x$n) - 2) * sum(x$n) / prod(x$n))
c(ADP, cse)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**11.3**</span> **Mean and standard error of ratios and products**

### <span style="color:gray; font-family:Microsoft JhengHei;">**11.3.1**</span> **Concepts**

- First we have two variables $p$ and $q$
- The third variable $x = p \cdot q$
- The fourth variable $y = p / q$
$$\bar x = \bar p \cdot \bar q$$
$$\bar y = \bar p / \bar q$$
$$se_x = \sqrt{\frac{\bar p^2 n_q se_q^2 + \bar q^2 n_p se_p^2 + n_p se_p^2 n_q se_q^2}{n_p + n_q - 2}}$$
$$se_y = \frac{1}{\bar q} \sqrt {\frac{n_p se_p^2 + n_qse_q^2(\frac{\bar p}{\bar q})^2}{n_p + n_q - 2}}$$

### <span style="color:gray; font-family:Microsoft JhengHei;">**11.3.2**</span> **Example**

In the previous example, we got the concentrations of ATP and ADP in a tissue sample. what is the ratio of [ATP]/[ADP]?
```{r}
x <- data.frame(mean = c(3.25, ADP), n = c(8, 10), se = c(0.14, cse))
x
ratiox <- x$mean[1] / x$mean[2]
cse <- sqrt((x$n[1] * x$se[1] ^ 2 + x$n[2] * x$se[2] ^ 2 * ((x$mean[1] / x$mean[2]) ^ 2)) / (sum(x$n) - 2)) / x$mean[2]
c(ratiox, cse)
```

# <span style="color:gray; font-family:Microsoft JhengHei;">**12**</span> **Non-parametric hypothesis tests**

## <span style="color:gray; font-family:Microsoft JhengHei;">**12.1**</span> **Definition**

**Non-parametric hypothesis tests:**<br>
A hypothesis test that does not require any specific conditions concerning the shapes of <mark>population distributions</mark> or <mark>the values of population parameters</mark>. When we don't know the distribution of the population, the it is <mark>easier to perform</mark> than corresponding parametric tests but <mark>less efficient</mark> than parametric tests.

## <span style="color:gray; font-family:Microsoft JhengHei;">**12.2**</span> **Wilcoxon Rank-Sum test**

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.2.1**</span> **Concept**

Wilcoxon Rank-Sum test, also known as the Mann-Whitney U test, is a non-parametric test for <mark>comparing the equality of the medians of two independent samples</mark>. Its original hypothesis is that the medians of the two samples are equal, and the alternative hypothesis is that the medians of the two samples are not equal.<br>

- $H_0$: the medians of the two populations are equal.
  - Both samples are drawn randomly and independently.
  - The measures within the two samples are able to be ranked and hence must be continuous, discrete or ordinal.

The basic idea of this test is to combine the two samples, rank them in order of size, and then calculate how many of the rankings in each sample are less than or equal to the value of that sample. The sum of these rankings is then used as the test statistic. If the medians of the two samples are equal, the test statistic should be close to half the sum of the total rankings. If the medians of the two samples are not equal, then the test statistic should be far from half the sum of the total rankings.
$$U=\sum_{i=1}^n \sum_{j=1}^m S\left(X_i, Y_j\right)$$
$$S(X, Y)= \begin{cases}1, & \text { if } X>Y \\ \frac{1}{2}, & \text { if } X=Y \\ 0, & \text { if } X<Y\end{cases}$$

- $U$: The Wilcoxon Rank-Sum test statistic
- $X_1, \ldots, X_n$: an independent sample from $X$
- $Y_1, \ldots, Y_m$: an independent sample from $Y$

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.2.2**</span> **Example-1**

**Suppose we have two dataset x and y, calculate the U (U is the smaller rank sum of these two samples):**
```{r}
# Row data
x <- c(3, 7)
y <- c(2, 4, 5, 8, 9)
m <- length(x)
n <- length(y)
# One step
# The outer() function is the function used in R to perform various operations between two vectors, 
# returning the result of all operations between all elements of the two vectors.
U <- sum(outer(x, y, ">")) + sum(outer(x, y, "==")) * 0.5 +  sum(outer(x, y, "<")) * 0
U
```

**Here is the distribution of Wilcoxon Rank-Sum test statistic:**<br>
The larger of the m and n, the U more like normal distribution, approximately normal distribution by:<br>
$$\mu_U = mn/2$$
$$s_U = \sqrt{\frac{mn(m + n + 1)}{12}}$$
<center>![Wilcoxon Rank-Sum test](images/Wilcoxon Rank-Sum test.png)</center>

If there have ties, $s_U$ need to be corrected as:
$$s_U = \sqrt{\frac{mn(m + n + 1)}{12}  - \frac{mn\sum((T_i - 1) T_i(T_i+1))}{12(m + n)((m+n)^2-1)}}$$
<span style="color:gray"><center>*$T_i$ is the number of ties in the ith set of ties*</center></span><br>

Ties concept:
```{r}
# Duplicate value ranking
rank(c(1, 2, 2, 3))
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.2.3**</span> **Workflow**

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
# One step
wilcox.test(x, y)
dtf <- data.frame(value = c(x, y),
                  name = rep(c('x', 'y'), c(m, n)))
wilcox.test(value ~ name, data = dtf)
# Boxplot visualization
boxplot(x, y, horizontal = TRUE)
U_critical <- qwilcox(c(0.025, 0.975), m, n)
pwilcox(U, m, n) * 2
# Probability density function plot visualization
curve(dwilcox(x, m, n), from = -1, to = 15, n = 17, ylab = 'Probability distribution density', las = 1, type = 'S', ylim = c(0, 0.15))
abline(h = 0)
segments(x0 = c(U, U_critical), y0 = 0, x1 = c(U, U_critical), y1 = dwilcox(c(U, U_critical), m, n), col = c('blue', 'red', 'red'))
legend('topright', legend = c('Distribution curve', 'Critical values', 'U score'), col = c('black', 'red', 'blue'), lty = 1, cex = 0.7)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.2.4**</span> **Example-2**

The insect spray dataset for C, D and F (just the pick C and D). The number of insects that survived when treated with insecticide treatments.
```{r, fig.width = 6, fig.height = 4, fig.align='center', warning=FALSE}
# Row data
insect <- read.csv("data/InsectSprays.csv")
insect <- insect[insect$spray %in% c("C", "D"), ]
# Visualization
boxplot(bugs ~ spray, data = insect, horizontal = TRUE)
```
Use Shapiro test to test each of the group we treat to see if they are normal distribution:
```{r}
shapiro.test(insect$bugs[insect$spray == "C"])
shapiro.test(insect$bugs[insect$spray == "D"])
```
Instead, we could test whether the two medians are different:
```{r}
tapply(insect$bugs, insect$spray, median)
```

**$H_0$:** The median of the survived insects treated by C is equal to that by D.
```{r, warning=FALSE}
# Step by step
m <- sum(insect$spray == 'C')
n <- sum(insect$spray == 'D')
x <- insect$bugs[insect$spray == 'C']
y <- insect$bugs[insect$spray == 'D']
U1 <- sum(outer(x, y, ">")) + sum(outer(x, y, "==")) * 0.5
U2 <- sum(outer(y, x, ">")) + sum(outer(y, x, "==")) * 0.5
U <- min(c(U1, U2))
U_critical <- qwilcox(c(0.025, 0.975), m, n)
pwilcox(U, m, n) * 2
# Approximately z distribution
U_mu <- m * n / 2
U_sd <- sqrt(m * n * (m + n + 1) / 12)
z_score <- (U - U_mu)/U_sd
pnorm(z_score) * 2 
# Determine if there is a significant difference between those two sprays
median(outer(insect$bugs[insect$spray == 'C'], insect$bugs[insect$spray == 'D'], "-"))
# One step
wilcox.test(bugs ~ spray, data = insect, conf.int=TRUE)
```

<details>
  <summary>The meaning of each parameter in this table</summary>
- W: the Wilcoxon test statistic U.
- We are 95% certain that the median difference between spray D and C across the population will be between 1 and 4 bugs.
- It does not estimate the difference in medians but rather the median of the difference (between the two samples)
</details>

**Decision:** Reject $H_0$<br>
**Conclusion:** There is a significant difference in insecticide effectiveness.

## <span style="color:gray; font-family:Microsoft JhengHei;">**12.3**</span> **Wilcoxon Signed-Rank test**

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.3.1**</span> **Concept**

Test whether the median of the observed differences deviates enough from zero, based on paired samples. Roughly a <mark>non-parametric version of paired t-test</mark>.<br>
**$H_0$:** the medians of the two populations are equal.

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.3.2**</span> **Example**

Ten people take part in a weight-loss program. They weigh before starting the program, and weigh again after the one-month program. Does the program have effect on the weight?

```{r, warning=FALSE}
# Row data
wl <- data.frame(
  id = LETTERS[1:10],
  before = c(198, 201, 210, 185, 204, 156, 167, 197, 220, 186),
  after = c(194, 203, 200, 183, 200, 153, 166, 197, 215, 184))
# Step by step
n <- nrow(wl)
d <- wl$after - wl$before
R <- rank(abs(d)) * abs(d) / d # signed ranks of the differences
W <- sum(R, na.rm = TRUE)
sW <- sqrt(n * (n + 1) * (2 * n + 1) / 6) # population standard deviation of W
z <- (abs(W) - 0.5) / sW
z_critical <- qnorm(p = c(0.025, 0.975)) # alpha = 0.05
pnorm(z, lower.tail = FALSE) * 2
# One step
wilcox.test(wl$before, wl$after, paired = TRUE, conf.int = TRUE, correct = FALSE)
```

**Decision:** As $p < 0.05$, reject $H_0$.<br>
**Conclusion:** The two population medians are different at $\alpha = 0.05$. The program has effect on the weight.

## <span style="color:gray; font-family:Microsoft JhengHei;">**12.4**</span> **Kruskal-Wallis test**

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.4.1**</span> **Concept**

Test whether three or more population medians are equal. Roughly a <mark>non-parametric version of ANOVA</mark><br>
**$H_0$:** the medians of the populations are equal.

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.4.2**</span> **Example**

The insect spray dataset for C, D, and F. The number of insects that survived when treated with insecticide treatments.<br>
Do any difference in the number of insects that survived when treated with multiple available insecticide treatments?
```{r, fig.width = 6, fig.height = 4, fig.align='center', warning=FALSE}
# Row data
insect <- read.csv("data/InsectSprays.csv")
# Visualization
boxplot(bugs ~ spray, data = insect, horizontal = TRUE, notch = TRUE)
shapiro.test(insect$bugs[insect$spray == "C"])  # Normal distribution
shapiro.test(insect$bugs[insect$spray == "D"])  # Normal distribution
shapiro.test(insect$bugs[insect$spray == "F"])  # Not normal distribution
# Determine if there is a significant difference between those three sprays
tapply(insect$bugs, insect$spray, median)
# One step
kruskal.test(bugs ~ spray, data = insect)
```
**Decision:** As $p < 0.05$, reject H0.<br>
**Conclusion:** There is a significant difference in insecticide effectiveness.

## <span style="color:gray; font-family:Microsoft JhengHei;">**12.5**</span> **Friedman’s test**

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.5.1**</span> **Concept**

Test whether three or more population medians are equal for repeated measures. Roughly a <mark>non-parametric version of repeated measures ANOVA</mark>. <u>More powerful than ANOVA for very skewed (heavy tail) distributions</u>.
$$F_{r}=\frac{12}{n k(k+1)}\left(T_{1}^{2}+T_{2}^{2}+\ldots+T_{k}^{2}\right)-3 n(k+1)$$

### <span style="color:gray; font-family:Microsoft JhengHei;">**12.5.2**</span> **Example**

```{r}
# Row data
dtf <- data.frame(
  before = c(198, 201, 210, 185, 204, 156, 167, 197, 220, 186),
  one = c(194, 203, 200, 183, 200, 153, 166, 197, 215, 184),
  two = c(191, 200, 192, 180, 195, 150, 167, 195, 209, 179),
  three = c(188, 196, 188, 178, 191, 145, 166, 192, 205, 175)
)
rownames(dtf) <- LETTERS[1:10]
k <- ncol(dtf)
n <- nrow(dtf)
```
Calculate the Friedman test statistic:
```{r}
# Rank of each group
dtf_rank <- t(apply(dtf, MARGIN = 1, rank))
dtf_rank
# Method-1 of Chi-square value
rank_sum <- colSums(dtf_rank)
chi_sq <- 12 / (n * k * (k + 1)) * sum(rank_sum ^ 2) - 3 * n * (k + 1)
# Method-2 of Chi-square value
rank_mean <- colMeans(dtf_rank)
rank_overall <- mean(1:k)
ssb <- n * sum((rank_mean - rank_overall) ^ 2)
chi_sq <- 12 * ssb / (k * (k + 1))
chi_sq
# Critical point
chi_critical <- qchisq(0.05, df = k - 1, lower.tail = FALSE)
chi_critical
# P-value
p_value <- pchisq(chi_sq, df = k - 1, lower.tail = FALSE)
p_value
# One step
friedman.test(as.matrix(dtf))
```
<span style="color:gray">Tips: the sample is too small, so the results calculated manually may different from those using the R function which uses more accurate mathematical methods to calculate the value of the statistic.</span>

# <span style="color:gray; font-family:Microsoft JhengHei;">**13**</span> **Multiple linear regression**

## <span style="color:gray; font-family:Microsoft JhengHei;">**13.1**</span> **Definition**

- **Linear Regression:** A statistical method to determine the independent quantitative relationship between one or more predictor variables and one dependent variable.
  - **Simple Linear Regression:** Only <mark>one</mark> predictor variable.
  - **Multiple linear regression:** <mark>Two or more</mark> predictor variables.
- **Selection** of predictor variables:
  - The predictor variables must have a significant influence on the dependent variable and show a close linear correlation.
  - The predictor variables should be mutually exclusive. The degree of correlation between independent variables should not be higher than the degree of correlation between independent variables and dependent variables.
  - The predictor variables should have complete statistical data, and their predicted values can be easily determined.
- **Model:** $$\begin{array}{*{20}{l}}
{{y_1} = {\beta _0} + {\beta _1}{X_{11}} + {\beta _2}{X_{12}}... + {\beta _k}{X_{1k}} + {\varepsilon _1}}\\
{{y_2} = {\beta _0} + {\beta _1}{X_{21}} + {\beta _2}{X_{22}}... + {\beta _k}{X_{2k}} + {\varepsilon _2}}\\
{....}\\
{y_i} = {\beta _0} + {\beta _1}{X_{i1}} + {\beta _2}{X_{i2}}... + {\beta _k}{X_{ik}} + {\varepsilon _i}\\
....\\
y_n = {\beta _0} + {\beta _1}{X_{n1}} + {\beta _2}{X_{n2}}... + {\beta _k}{X_{nk}} + \varepsilon _n
\end{array}$$
$$\begin{array}{*{20}{l}}
{\begin{array}{*{20}{l}}
{{\bf{Y = (}}{{\bf{y}}_{\bf{1}}}{\bf{,}}{{\bf{y}}_{\bf{2}}}{\bf{,}}...{\bf{,}}{{\bf{y}}_{\bf{n}}}{{\bf{)}}^{\bf{T}}}}\\
{{\bf{\beta  = (}}{{\bf{\beta }}_{\bf{1}}}{\bf{,}}{{\bf{\beta }}_{\bf{2}}}{\bf{,}}...{\bf{,}}{{\bf{\beta }}_{\bf{k}}}{{\bf{)}}^{\bf{T}}}}
\end{array}}\\
{{\bf{\varepsilon  = (}}{{\bf{\varepsilon }}_{\bf{1}}}{\bf{,}}{{\bf{\varepsilon }}_{\bf{2}}}{\bf{,}}...{\bf{,}}{{\bf{\varepsilon }}_{\bf{n}}}{{\bf{)}}^{\bf{T}}}}
\end{array}$$
$${\bf{X}} = \left( {\begin{array}{*{20}{c}}
1 & {X_{11}}& {X_{12}} & \ldots &{{X_{1k}}}\\
  \vdots&\vdots &\vdots& \ddots & \vdots \\
1& {X_{n1}}&{X_{n2}}&\cdots&{{X_{nk}}}
\end{array}} \right)$$
$$\bf{Y = X\beta  + \varepsilon }$$

  - $X$: predictor variable
  - $y$: dependent variable
  - $\beta_k$: regression coefficient
  - $\epsilon$: effect of other random factors.
  - The least-squares estimator of $\beta$: $$\bf{\beta  = (X'X)^{-1}X'Y}$$
  - The least square estimation of random error variance: $${\sigma ^2}{\rm{ = }}\frac{{{e^T}e}}{{n - k - 1}}$$
- Workflow:
  - Fit the model by `lm()`
  - Diagnose the model by `summary()`
  - Optimize the model by `step()`

## <span style="color:gray; font-family:Microsoft JhengHei;">**13.2**</span> **Visualization**

```{r}
# Import the dataset which is about the US Crime Data
data(usc, package = "ACSWR")
```
```{r, fig.width = 10, fig.height = 8, fig.align='center'}
# Draw the pair plot to visualize the correlation
## pairs(usc)
GGally::ggpairs(usc)
# From the plot above, we can calculate that there have high correlation coefficient between Ex0 and Ex1
cor(usc$Ex0,usc$Ex1)
# Show the correlation coefficient directly
ucor <- cor(usc)
ucor
# Draw the correlation plot divided by two part (numerical & graphic)
corrplot::corrplot(ucor, order = 'AOE', type = "upper", method = "number")
corrplot::corrplot(ucor, order = "AOE", type = "lower", method = "ell", 
                   diag = FALSE, tl.pos = "n", cl.pos = "n", add = TRUE)
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**13.3**</span> **Fit the model**

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.3.1**</span> **Analysis**
```{r}
# Do linear regression
crime_rate_lm <- lm(R ~ ., data = usc)
summary(crime_rate_lm)
# Computes confidence intervals for each parameters in this linear regression model
confint(crime_rate_lm)
# Compute analysis of variance tables for this linear regression model
anova(crime_rate_lm)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.3.2**</span> **Conclusion**

- The intercept terms, Age, ED, U2, and X are significant variables to explain the crime rate. The 95% confidence intervals also confirm it.
- The model is significant: $p < 0.05$, adjusted $R^2 = 0.6783$.

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.3.3**</span> **The difference between $R^2$ and Adj-$R^2$**

```{r}
get_R2 <- function(x, method){
  round(summary(lm(usc$R ~ as.matrix(usc[, 2:x])))[[method]], 3)
}
dtf_R2 <- data.frame(n = 1:13,
                     R2 = sapply(2:14, get_R2, method = 'r.squared'),
                     AdjR2 = sapply(2:14, get_R2, method = 'adj.r.squared'))
library(ggplot2)
library(tidyr)
dtf_R2 |> 
  pivot_longer(-n) |> 
  ggplot() + 
  geom_point(aes(n, value, col = name)) + 
  geom_line(aes(n, value, col = name))
```

## <span style="color:gray; font-family:Microsoft JhengHei;">**13.4**</span> **Evaluate & improve the model**

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.4.1**</span> **Issue**

<mark>**Multicollinearity:**</mark>

- multi-: multiple columns
- col-: relationship
- linearity: linear

**Problems:**

1. Imprecise estimates of $\beta$
2. The t-tests may fail to reveal significant factors
3. Missing importance of predictors

```{r, fig.width = 6, fig.height = 4, fig.align='center'}
# Single linear regression
data(Euphorbiaceae, package = 'gpk')
dtf <- data.frame(x1 = Euphorbiaceae$GBH,
                  y = Euphorbiaceae$Height)
plot(dtf)
lm(y ~ x1, data = dtf) |> summary()
# Multiply linear regression
dtf$x2 <- jitter(dtf$x)  # Add some random error to data
pairs(dtf)
lm(y ~ x1 + x2, data = dtf) |> summary()
```
<a id="Variance inflation factor (VIF)"></a>

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.4.2**</span> **Variance inflation factor (VIF)**

$$\mathrm{VIF}_j = \frac{1}{1-R_j^2}$$

- $\mathrm{VIF}_j$**:** $VIF$ for the $j$-th variable
- $R^2_j$**:** $R^2$ from the regression of the $j$-th explanatory variable on the remaining explanatory variables.

Remove the `R` from usc dataset:
```{r}
uscrimewor <- usc[, -1]
names(uscrimewor)
```

Calculate the $VIF$:
```{r}
# Compute the VIF for Ex0
usc_lm_Ex0 <- summary(lm(Ex0  ~ ., data = uscrimewor))
1 / (1 - usc_lm_Ex0$r.squared)
# Compute all of the VIF
faraway::vif(uscrimewor)
```

<mark>**Filter:** $VIF > 10$ ($R^2 > 0.9$)</mark><br><br>
Drop the variable with highest $VIF$ and then update the model until all $VIF \leq 10$:
```{r}
uscrimewor2 <- uscrimewor[, c('Age','S','Ed','Ex0','LF','M','N','NW','U1','U2','W','X')]
faraway::vif(uscrimewor2)
crime_rate_lm2 <- lm(R ~ Age + S + Ed + Ex0 + LF + M + N + NW + U1 + U2 + W + X, usc)
summary(crime_rate_lm2)
```

**Conclusion:** The 12 explanatory variables account for 76.7% of the variability in the crime rates of the 47 states.

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.4.3**</span> **Eigen System Analysis**

```{r}
uscrimewor <- as.matrix(uscrimewor)
usc_stan <- scale(uscrimewor)
x1x_stan <- t(usc_stan) %*% usc_stan
usc_eigen <- eigen(x1x_stan)
usc_kappa <- max(usc_eigen$values) / min(usc_eigen$values)  # Condition number k
```

- $k$ < 100: no multicollinearity
- 100 < $k$ < 1000: moderate multicollinearity
- $k$ > 1000: severe multicollinearity

```{r}
usec_index <- max(usc_eigen$values) / usc_eigen$values  # Condition indices
usc_eigen$vectors[, usec_index > 1000]
```
We still don't know which one should be remove, so we'd better use [Variance inflation factor (VIF)](#Variance inflation factor (VIF)).

## <span style="color:gray; font-family:Microsoft JhengHei;">**13.5**</span> **Simply the model**

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.5.1**</span> **Backward selection**

1. Start with all the predictors in the model.
2. Remove the predictor with highest p-value greater than $\alpha$ (= 0.05 usually).
3. Refit the model and go to 2.
4. Stop when all p-values are less than $\alpha$.

```{r}
# This function is used to calculate the coefficients of the linear regression model and sort them from largest to smallest by P-value
get_p <- function(model){
  smry2 <- data.frame(summary(model)$coefficients)
  smry2[order(-smry2$Pr...t..), ]
}
get_p(crime_rate_lm2)
# Update-1
crime_rate_lm3 <- update(crime_rate_lm2, . ~ . - NW)
get_p(crime_rate_lm3)
# Update-2
crime_rate_lm4 <- update(crime_rate_lm3, . ~ . - LF)
get_p(crime_rate_lm4)
# Update-3
crime_rate_lm5 <- update(crime_rate_lm4,.~.-N)
get_p(crime_rate_lm5)
# Update-4
crime_rate_lm6 <- update(crime_rate_lm5,.~.-S)
get_p(crime_rate_lm6)
# Update-5
crime_rate_lm7 <- update(crime_rate_lm6,.~.-M)
get_p(crime_rate_lm7)
# Update-6
crime_rate_lm8 <- update(crime_rate_lm7,.~.-U1)
get_p(crime_rate_lm8)
# Update-7
crime_rate_lm9 <- update(crime_rate_lm8,.~.-W)
get_p(crime_rate_lm9)
# Final summary
summary(crime_rate_lm9)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.5.2**</span> **Forward selection**

1. Start with no variables in the model.
2. For all predictors not in the model, check their p-value if they are added to the model. Choose the one with lowest p-value less than alpha critical.
3. Continue until no new predictors can be added.

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.5.3**</span> **AIC selection**

Akaike Information Criteria (AIC) **principle**: <mark>big -> bad</mark>
```{r}
crime_rate_aic <- step(crime_rate_lm, direction = "both")
summary(crime_rate_aic)
```

### <span style="color:gray; font-family:Microsoft JhengHei;">**13.5.4**</span> **Result**

**According to the backward selection:**
```{r}
equatiomatic::extract_eq(crime_rate_lm9, use_coefs = TRUE)
stargazer::stargazer(crime_rate_lm9, type = 'text')
```
The model shows that the variables Age, Ed, Ex0, U2, and X explain 73% of the variability in the crime rates.<br>

**According to the AIC selection:**
```{r}
equatiomatic::extract_eq(crime_rate_aic, use_coefs = TRUE)
stargazer::stargazer(crime_rate_aic, type = 'text')
```
The model shows that the variables Age, Ed, Ex0, U2, W, and X explain 75% of the variability in the crime rates.

# <span style="color:gray; font-family:Microsoft JhengHei;">**14**</span> **Logistic regression**

<span style="color:#008888">To be continue...</span>

# <span style="color:gray; font-family:Microsoft JhengHei;">**15**</span> **Poisson regression**

<span style="color:#008888">To be continue...</span>

# <span style="color:gray; font-family:Microsoft JhengHei;">**16**</span> **Non-linear regression**

<span style="color:#008888">To be continue...</span>

# <span style="color:gray; font-family:Microsoft JhengHei;">**17**</span> **Principal component analysis**

<span style="color:#008888">To be continue...</span>

# <span style="color:gray; font-family:Microsoft JhengHei;">**18**</span> **Cluster analysis**

<span style="color:#008888">To be continue...</span>

# **[SessionInfo:]{style="color:green"}**

```{r, echo=FALSE}
sessionInfo()
```